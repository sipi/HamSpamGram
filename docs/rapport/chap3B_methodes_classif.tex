\textit{L’objectif de cette étape est de générer un modèle de notre attribut CLASS en fonction des valeurs des attributs sélectionnées à l’étape précédente. En utilisant plusieurs algorithmes de classification, également vus et pas vus en cours, on a comparé leur performance sur les différents représentations obtenues à l’étape 2 selon les mesures de \og ACCURACY, PRECISION et RECALL \fg{} , afin d’en trouver le meilleur modèle.}

\subsection{Description des algorithmes}
\subsubsection {Arbre de décision - J48}
L'algorithme de classification par arbre de décision J48 est basé principalement sur l'algorithme C4.5. Il permet entre autres, d'élaguer l'arbre généré afin de simplifier son interprétation.  

\subsection{Mise en oeuvre}

Afin d'appliquer ces quatre algorithmes sur l'ensemble des fichiers générés dans la partie 3a, nous avons décidé d'écrire un petit script bash :
//todo{Thibaut} source : script.sh

\subsection{Résultats}

Après avoir exécuté les différents algorithmes, nous pouvons faire plusieurs remarques.

\subsubsection{Sélection d'attributs}
Nous pouvons observer, grâce aux différents seuils choisis pour l'algorithme de selection d'attributs \og Ranker \fg{}, que plus le nombre d'attributs selectionnés est grands plus le nombre de SMS mal classés est faible.

\subsubsection{Meilleur algorithme}
    le meilleur algo semble etre NBTree

\subsubsection{Meilleur représentation des données}
    le meilleur modèle semble être le boolean 

    l'algo KStar a une bonne précision sur les SPAM (très peu de ham classé comme SPAM)



